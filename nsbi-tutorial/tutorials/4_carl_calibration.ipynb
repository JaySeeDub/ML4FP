{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "529af8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib, matplotlib.pyplot as plt\n",
    "import hist\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import lightning\n",
    "\n",
    "from physics.analysis import zz4l, zz2l2v\n",
    "from datasets.balanced import BalancedDataset\n",
    "from nsbi import carl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a792a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"lualatex\",\n",
    "    \"text.usetex\": True,\n",
    "    \"pgf.rcfonts\": False,  # Don't override with default matplotlib fonts\n",
    "    \"pgf.preamble\": \"\", \n",
    "})\n",
    "lw = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd7ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = 'run/h4l'\n",
    "batch_size = 1024\n",
    "\n",
    "# (events_n_train, events_n_test), (events_d_train, events_d_test), scaler, carl_model = carl.utils.load_results(run_dir, 'sbi_over_bkg')\n",
    "# features = ['l1_pt', 'l1_eta', 'l1_phi', 'l1_energy', 'l2_pt', 'l2_eta', 'l2_phi', 'l2_energy', 'l3_pt', 'l3_eta', 'l3_phi', 'l3_energy', 'l4_pt', 'l4_eta', 'l4_phi', 'l4_energy']\n",
    "\n",
    "(events_n_train, events_n_test), (events_d_train, events_d_test), scaler, carl_model = carl.utils.load_results(run_dir, 'sig_over_bkg')\n",
    "features = ['l1_pt', 'l1_eta', 'l1_phi', 'l1_energy', 'l2_pt', 'l2_eta', 'l2_phi', 'l2_energy', 'l3_pt', 'l3_eta', 'l3_phi', 'l3_energy', 'l4_pt', 'l4_eta', 'l4_phi', 'l4_energy']\n",
    "\n",
    "# output_dir = 'run/presel/h2l2v/'\n",
    "# (events_nnom_traieveevents_n_qq_test), (events_d_train, events_d_test), scaler, carl_model = carl.utils.load_results(output_dir)\n",
    "# features = [\"l1_pt\", \"l1_eta\", \"l1_phi\", \"l1_energy\", \"l2_pt\", \"l2_eta\", \"l2_phi\", \"l2_energy\", \"met\", \"met_phi\"]\n",
    "# batch_size = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df2a9cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/afs/ipp-garching.mpg.de/home/t/taepa/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/afs/ipp-garching.mpg.de/home/t/taepa/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/afs/ipp-garching.mpg.de/home/t/taepa/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    }
   ],
   "source": [
    "r_d_train = carl.utils.get_likelihood_ratio(events_d_train, features, scaler, carl_model)\n",
    "r_d_test = carl.utils.get_likelihood_ratio(events_d_test, features, scaler, carl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c709a1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998148104389868\n",
      "0.9996756441161829\n"
     ]
    }
   ],
   "source": [
    "one_train = r_d_train * torch.tensor(events_d_train.probabilities)\n",
    "print(torch.sum(one_train).numpy())\n",
    "\n",
    "one_test = r_d_test * torch.tensor(events_d_test.probabilities)\n",
    "print(torch.sum(one_test).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92a9059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = BalancedDataset(events_n_test, events_d_test, features=features, scaler=scaler)\n",
    "dl_test = torch.utils.data.DataLoader(torch.tensor(ds_test.X, dtype=torch.float32), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a85b2a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/afs/ipp-garching.mpg.de/home/t/taepa/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f13a10de254d5d87369023a6d55122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = lightning.Trainer(accelerator='gpu', devices=1)\n",
    "\n",
    "# predictions_train = torch.concatenate(trainer.predict(carl_model, dataloaders=[dl_train]), axis=0).detach().numpy()\n",
    "# predictions_val_batches = trainer.predict(carl_model, dl_val)\n",
    "predictions_test_batches = trainer.predict(carl_model, dl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2048b5bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26fbc3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5050, 0.5037, 0.5030,  ..., 0.4785, 0.5036, 0.5044])\n"
     ]
    }
   ],
   "source": [
    "# predictions_val = torch.cat(predictions_val_batches).detach().numpy()\n",
    "# targets_val = validation_data.s\n",
    "# weights_val = validation_data.w * len(validation_data)\n",
    "\n",
    "predictions_test = torch.cat(predictions_test_batches).detach().numpy()\n",
    "predictions_test /= torch.sum(one_train)\n",
    "\n",
    "targets_test = ds_test.s\n",
    "weights_test = ds_test.w * len(ds_test)\n",
    "print(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8643934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_bins = np.linspace(0.0, 1.0, 41)\n",
    "s_centers = (s_bins[:-1] + s_bins[1:])/2\n",
    "s_nbins = len(s_bins) -1\n",
    "s_widths = (s_bins[1:] - s_bins[:-1])/2\n",
    "\n",
    "s_bins = np.linspace(0.0, 1.0, 41)\n",
    "s_centers = (s_bins[:-1] + s_bins[1:])/2\n",
    "s_nbins = len(s_bins) -1\n",
    "s_widths = (s_bins[1:] - s_bins[:-1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "608b604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_953008/3745675514.py:11: RuntimeWarning: invalid value encountered in divide\n",
      "  s_true = sig_per_bin/(sig_per_bin+bkg_per_bin)\n",
      "/tmp/ipykernel_953008/3745675514.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  (sig_err * bkg_per_bin / (sig_per_bin + bkg_per_bin)**2)**2 +\n",
      "/tmp/ipykernel_953008/3745675514.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  (bkg_err * sig_per_bin / (sig_per_bin + bkg_per_bin)**2)**2\n"
     ]
    }
   ],
   "source": [
    "p = predictions_test\n",
    "t = targets_test\n",
    "w = weights_test\n",
    "\n",
    "pred_binned = [p[(p >= s_bins[i]) & (p < s_bins[i+1])] for i in range(s_nbins)]\n",
    "targets_binned = [t[(p >= s_bins[i]) & (p < s_bins[i+1])] for i in range(s_nbins)]\n",
    "weights_binned = [w[(p >= s_bins[i]) & (p < s_bins[i+1])] for i in range(s_nbins)]\n",
    "\n",
    "sig_per_bin = np.array([np.sum((targets_binned[i]==1.0) * weights_binned[i]) for i in range(s_nbins)])\n",
    "bkg_per_bin = np.array([np.sum((targets_binned[i]==0.0) * weights_binned[i]) for i in range(s_nbins)])\n",
    "s_true = sig_per_bin/(sig_per_bin+bkg_per_bin)\n",
    "\n",
    "sig_err = np.sqrt(np.array([np.sum((targets_binned[i]==1.0) * weights_binned[i] * weights_binned[i]) for i in range(s_nbins)]))\n",
    "bkg_err = np.sqrt(np.array([np.sum((targets_binned[i]==0.0) * weights_binned[i] * weights_binned[i]) for i in range(s_nbins)]))\n",
    "s_err = np.sqrt(\n",
    "    (sig_err * bkg_per_bin / (sig_per_bin + bkg_per_bin)**2)**2 +\n",
    "    (bkg_err * sig_per_bin / (sig_per_bin + bkg_per_bin)**2)**2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "786a065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2,1, gridspec_kw={'height_ratios': [4,1]}, figsize=(5,5), sharex=True)\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax1.errorbar([0,1], [0,1], color='grey', linestyle='--', linewidth=lw, label='$\\\\mathrm{MC}$')\n",
    "ax1.errorbar(s_centers, s_true, xerr=s_widths, yerr=s_err, color='cornflowerblue', linestyle='none', linewidth=lw,  label='$\\\\mathrm{NSBI}$')\n",
    "\n",
    "ax1.set_ylim(0,1)\n",
    "ax1.set_ylabel('$\\\\mathrm{MC\\\\ estimate}\\\\ \\\\frac{p_{q\\\\bar{q}}(x)}{ p_{q\\\\bar{q}}(x) + p_{gg}(x) }$', fontsize=15)\n",
    "\n",
    "ax1.legend(frameon=False, fontsize=12)\n",
    "\n",
    "ax2.errorbar([0,1], [0,0], color='grey', linestyle='--', linewidth=lw)\n",
    "ax2.errorbar(s_centers, np.array(s_true)-np.array(s_centers), xerr=s_widths, yerr=s_err, color='cornflowerblue', linestyle='none', linewidth=lw)\n",
    "\n",
    "ax2.set_xlim(0,1)\n",
    "ax2.set_xlabel('$\\\\mathrm{NSBI\\\\ estimate}\\\\ \\\\hat{s}(x)$', fontsize=15)\n",
    "ax2.set_ylabel('$\\\\mathrm{Residual}$', fontsize=15)\n",
    "ax2.set_ylim(-0.075, 0.075)\n",
    "ax2.yaxis.set_ticks([-0.05, 0.05])\n",
    "\n",
    "ax1.tick_params(labelsize=12)\n",
    "ax2.tick_params(labelsize=12)\n",
    "\n",
    "# ax1.text(0.96 ,0.12, '$pp \\\\rightarrow ZZ \\\\rightarrow 4\\\\ell$', transform=ax1.transAxes, ha='right', va='bottom', fontsize=12)\n",
    "ax1.text(0.96 ,0.12, '$pp \\\\rightarrow ZZ \\\\rightarrow 2\\\\ell 2\\\\nu$', transform=ax1.transAxes, ha='right', va='bottom', fontsize=12)\n",
    "ax1.text(0.96 ,0.04, '$\\\\sqrt{s} = 14\\\\,\\\\mathrm{TeV}$', transform=ax1.transAxes, ha='right', va='bottom', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0)\n",
    "\n",
    "fig.canvas.draw()  # update positions\n",
    "ax1_pos, ax2_pos = ax1.get_position(), ax2.get_position()\n",
    "ax2.set_position([ax1_pos.x0, ax2_pos.y0, ax1_pos.width, ax2_pos.height]) # align 2nd x-axis with 1st\n",
    "\n",
    "ax2.xaxis.set_tick_params(which='both', labeltop=False, top=True)\n",
    "\n",
    "plt.savefig('carl_calibration.pdf', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43a72076",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_denominator_test = carl_model(torch.tensor(scaler.transform(events_d_test.kinematics[features].to_numpy()), dtype=torch.float32)).detach().numpy().ravel()\n",
    "# predictions_denominator_val = carl_model(torch.tensor(scaler.transform(events_ninator_val.kinematics[features].to_numpy()), dtype=torch.float32)).detach().numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af9c2c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4l_numerator = events_n_test.calculate(zz4l.FourLeptonSystem()).kinematics['4l_mass']\n",
    "m4l_denominator = events_d_test.calculate(zz4l.FourLeptonSystem()).kinematics['4l_mass']\n",
    "xobs_numerator = m4l_numerator\n",
    "xobs_denominator = m4l_denominator\n",
    "xbins = np.concatenate([np.arange(180,250,10), np.arange(250,500,50), np.arange(500,750,125), np.arange(750,1100,250)])\n",
    "xmin, xmax = 180, 1000\n",
    "xwidths = np.diff(xbins)\n",
    "xcenters = xbins[:-1] + xwidths/2\n",
    "xlabel = '$m_{ZZ}\\\\ \\\\mathrm{[GeV]}$'\n",
    "y2_min, y2_max = 0.5, 3.5\n",
    "y3_min, y3_max = 0.85, 1.15\n",
    "\n",
    "# mtzz_numerator = events_n_test.calculate(zz2l2v.ZZ2L2V()).kinematics['zz_mt']\n",
    "# mtzz_denominator = events_d_test.calculate(zz2l2v.ZZ2L2V()).kinematics['zz_mt']\n",
    "# xobs_numerator = mtzz_numerator\n",
    "# xobs_denominator = mtzz_denominator\n",
    "# xbins = np.concatenate([np.arange(250,300,10), np.arange(300,400,25), np.arange(400,500,50), np.arange(500,1100,100)])\n",
    "# xmin, xmax = 250, 1000\n",
    "# xwidths = np.diff(xbins)\n",
    "# xcenters = xbins[:-1] + xwidths/2\n",
    "# xlabel = '$m_{\\\\mathrm T}^{ZZ}\\\\ \\\\mathrm{[GeV]}$'\n",
    "# y2_min, y2_max = 0.75, 1.75\n",
    "# y3_min, y3_max = 0.85, 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82e84afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_953008/2950299888.py:40: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "h_num_mc = hist.Hist(hist.axis.Variable(xbins), storage=hist.storage.Weight())\n",
    "h_num_mc.fill(xobs_numerator, weight=events_n_test.probabilities)\n",
    "\n",
    "h_denom = hist.Hist(hist.axis.Variable(xbins), storage=hist.storage.Weight())\n",
    "h_denom.fill(xobs_denominator, weight=events_d_test.probabilities)\n",
    "\n",
    "h_num_carl = hist.Hist(hist.axis.Variable(xbins), storage=hist.storage.Weight())\n",
    "h_num_carl.fill(xobs_denominator, weight=events_d_test.probabilities * (predictions_denominator_test / (1 - predictions_denominator_test)))\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1,gridspec_kw={'height_ratios': [2, 1, 1]},figsize=(5,6), layout='constrained', sharex=True)\n",
    "\n",
    "ax1.stairs(h_num_carl.values()/xwidths, h_num_carl.axes[0].edges, color='cornflowerblue', linewidth=lw, label='$q\\\\bar{q} \\\\to ZZ\\\\ (\\\\mathrm{NSBI})$')\n",
    "ax1.stairs(h_num_mc.values()/xwidths, h_num_mc.axes[0].edges, color='blue', linestyle='--', linewidth=lw, label='$q\\\\bar{q} \\\\to ZZ\\\\ (\\\\mathrm{MC})$')\n",
    "ax1.stairs(h_denom.values()/xwidths, h_denom.axes[0].edges, color='black', linestyle='--', linewidth=lw, label='$gg(\\\\to h^{\\\\ast}) \\\\to ZZ$')\n",
    "\n",
    "ax2.stairs(h_num_carl.values()/h_denom.values(), h_num_mc.axes[0].edges, color='cornflowerblue', linewidth=lw)\n",
    "ax2.stairs(h_num_mc.values()/h_denom.values(), h_num_mc.axes[0].edges, color='blue', linestyle='--', linewidth=lw)\n",
    "ax2.stairs(h_denom.values()/h_denom.values(), h_denom.axes[0].edges, color='black', linestyle='--', linewidth=lw)\n",
    "\n",
    "ax3.stairs(h_num_mc.values()/h_num_mc.values(), xbins, color='blue', linestyle='--', linewidth=lw)\n",
    "ax3.errorbar(xcenters, h_num_carl.values()/h_num_mc.values(), yerr=np.sqrt(h_num_carl.variances())/h_num_carl.values(), xerr=xwidths/2, fmt='none', color='cornflowerblue', linewidth=lw)\n",
    "\n",
    "ax1.legend(frameon=False, fontsize=12)\n",
    "\n",
    "ax1.set_yscale('log')\n",
    "ax2.set_ylim(y2_min, y2_max)\n",
    "ax3.set_ylim(y3_min, y3_max)\n",
    "\n",
    "ax1.tick_params(labelsize=12)\n",
    "ax2.tick_params(labelsize=12)\n",
    "ax3.tick_params(labelsize=12)\n",
    "\n",
    "ax1.set_ylabel('$\\\\mathrm{Density\\\\ of\\\\ events\\\\ [1/GeV]}$', fontsize=15, loc='top')\n",
    "ax2.set_ylabel('$p_{q\\\\bar{q}}/p_{gg}$', fontsize=15)\n",
    "ax3.set_ylabel('$\\\\mathrm{NSBI}/\\\\mathrm{MC}$', fontsize=12)\n",
    "\n",
    "ax3.set_xlabel(xlabel, fontsize=12)\n",
    "ax3.set_xlim(xmin, xmax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0)\n",
    "\n",
    "plt.savefig('carl_reweight.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463579b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a39e446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
