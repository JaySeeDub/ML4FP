{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2285437c-72ac-42c7-a70e-655b8339ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import load_data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb33ea9e-e41d-4dc8-ae2e-340089f9924e",
   "metadata": {},
   "source": [
    "### Let's open the training and validation files containing examples for top quarks (signal) and QCD jets (background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89bbb048-dc2f-4f03-9f02-f3f4e53fb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/pscratch/sd/v/vmikuni/datasets'\n",
    "train_data = load_data('top',input_folder,batch=128,dataset_type='train',num_evt = 100_000)\n",
    "val_data = load_data('top',input_folder,batch=128,dataset_type='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aeec21c-cfe9-47e3-9250-e14724fddce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 781 batches of events for training and 3148 for validation\n"
     ]
    }
   ],
   "source": [
    "print (f\"Loading {len(train_data)} batches of events for training and {len(val_data)} for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f38a93c-14f3-49ec-90c7-65baeb1a10c8",
   "metadata": {},
   "source": [
    "### We Now need to create a model that will take the data as input and predict a label for each data entry. Let's create a config file with the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c62ed545-402a-4b3d-aa49-60c3926efd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'num_layers': 2,\n",
    "    'hidden_dim': 64,\n",
    "    'activation': nn.ReLU(), #https://docs.pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d2a3539-2431-4f5a-8910-f399b4920d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDeepSets(nn.Module):\n",
    "    def __init__(self, input_dim, config, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, config[\"hidden_dim\"])\n",
    "        \n",
    "        layers = []\n",
    "        for _ in range(config[\"num_layers\"]):\n",
    "            layers.append(nn.Linear(config[\"hidden_dim\"], config[\"hidden_dim\"]))\n",
    "            layers.append(config[\"activation\"])\n",
    "        self.hidden_layers = nn.ModuleList(layers)\n",
    "\n",
    "        self.output_layer = nn.Linear(config[\"hidden_dim\"], num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        zero_pad_mask = (inputs[:, :, 2] != 0).unsqueeze(-1).float()\n",
    "        x = self.input_layer(inputs) * zero_pad_mask\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x) * zero_pad_mask\n",
    "        x = x.mean(1)  # aggregate over particles\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a778d5c8-5f18-401b-b944-38422d1164ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleDeepSets(input_dim=4,config=config) #remember the inputs are delta eta, delta phi, log(pT), log(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f95bf4-8f95-4742-aa4b-dc6f3e211511",
   "metadata": {},
   "source": [
    "### Now we are going to create the training class that will train the model, but first, let's set up the learning rate and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73397f76-9973-4bad-9bf7-146a01408397",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "lr = 5e-4\n",
    "epochs = 100\n",
    "patience = 10 # Number of consecutive epochs to stop the training if the validation loss does not improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e6c7534-3b5f-4d2d-b53c-3f17389a9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = utils.Trainer(train_data,val_data,model,lr,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea3830-5f46-45eb-b27c-0478c17451de",
   "metadata": {},
   "source": [
    "### Let's train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb53f3c-c01d-4d0c-a16f-28fb5704a609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss=0.5546, validation loss=0.4841\n",
      "Epoch 2: train loss=0.3944, validation loss=0.3645\n",
      "Epoch 3: train loss=0.3616, validation loss=0.3529\n",
      "Epoch 4: train loss=0.3532, validation loss=0.3482\n",
      "Epoch 5: train loss=0.3485, validation loss=0.3544\n",
      "Epoch 6: train loss=0.3455, validation loss=0.3408\n",
      "Epoch 7: train loss=0.3436, validation loss=0.3409\n",
      "Epoch 8: train loss=0.3410, validation loss=0.3379\n",
      "Epoch 9: train loss=0.3415, validation loss=0.3392\n",
      "Epoch 10: train loss=0.3400, validation loss=0.3364\n",
      "Epoch 11: train loss=0.3393, validation loss=0.3373\n",
      "Epoch 12: train loss=0.3402, validation loss=0.3535\n",
      "Epoch 13: train loss=0.3381, validation loss=0.3397\n",
      "Epoch 14: train loss=0.3384, validation loss=0.3496\n",
      "Epoch 15: train loss=0.3371, validation loss=0.3377\n",
      "Epoch 16: train loss=0.3372, validation loss=0.3337\n",
      "Epoch 17: train loss=0.3359, validation loss=0.3353\n",
      "Epoch 18: train loss=0.3357, validation loss=0.3457\n",
      "Epoch 19: train loss=0.3351, validation loss=0.3414\n",
      "Epoch 20: train loss=0.3354, validation loss=0.3381\n",
      "Epoch 21: train loss=0.3357, validation loss=0.3392\n",
      "Epoch 22: train loss=0.3348, validation loss=0.3335\n",
      "Epoch 23: train loss=0.3346, validation loss=0.3381\n",
      "Epoch 24: train loss=0.3346, validation loss=0.3331\n",
      "Epoch 25: train loss=0.3338, validation loss=0.3338\n",
      "Epoch 26: train loss=0.3348, validation loss=0.3371\n",
      "Epoch 27: train loss=0.3344, validation loss=0.3326\n",
      "Epoch 28: train loss=0.3332, validation loss=0.3512\n",
      "Epoch 29: train loss=0.3338, validation loss=0.3322\n",
      "Epoch 30: train loss=0.3329, validation loss=0.3327\n",
      "Epoch 31: train loss=0.3339, validation loss=0.3318\n",
      "Epoch 32: train loss=0.3334, validation loss=0.3386\n",
      "Epoch 33: train loss=0.3327, validation loss=0.3327\n",
      "Epoch 34: train loss=0.3324, validation loss=0.3317\n",
      "Epoch 35: train loss=0.3329, validation loss=0.3308\n",
      "Epoch 36: train loss=0.3327, validation loss=0.3317\n",
      "Epoch 37: train loss=0.3330, validation loss=0.3329\n",
      "Epoch 38: train loss=0.3325, validation loss=0.3331\n",
      "Epoch 39: train loss=0.3324, validation loss=0.3394\n",
      "Epoch 40: train loss=0.3320, validation loss=0.3339\n",
      "Epoch 41: train loss=0.3318, validation loss=0.3339\n",
      "Epoch 42: train loss=0.3317, validation loss=0.3321\n",
      "Epoch 43: train loss=0.3317, validation loss=0.3309\n",
      "Epoch 44: train loss=0.3320, validation loss=0.3318\n",
      "Epoch 45: train loss=0.3322, validation loss=0.3302\n",
      "Epoch 46: train loss=0.3310, validation loss=0.3335\n",
      "Epoch 47: train loss=0.3316, validation loss=0.3304\n",
      "Epoch 48: train loss=0.3311, validation loss=0.3483\n",
      "Epoch 49: train loss=0.3317, validation loss=0.3311\n",
      "Epoch 50: train loss=0.3311, validation loss=0.3301\n",
      "Epoch 51: train loss=0.3313, validation loss=0.3314\n",
      "Epoch 52: train loss=0.3308, validation loss=0.3321\n",
      "Epoch 53: train loss=0.3306, validation loss=0.3329\n",
      "Epoch 54: train loss=0.3311, validation loss=0.3328\n",
      "Epoch 55: train loss=0.3311, validation loss=0.3348\n",
      "Epoch 56: train loss=0.3307, validation loss=0.3300\n",
      "Epoch 57: train loss=0.3310, validation loss=0.3303\n",
      "Epoch 58: train loss=0.3300, validation loss=0.3302\n",
      "Epoch 59: train loss=0.3307, validation loss=0.3305\n",
      "Epoch 60: train loss=0.3303, validation loss=0.3298\n",
      "Epoch 61: train loss=0.3300, validation loss=0.3300\n",
      "Epoch 62: train loss=0.3305, validation loss=0.3303\n",
      "Epoch 63: train loss=0.3303, validation loss=0.3298\n",
      "Epoch 64: train loss=0.3298, validation loss=0.3345\n",
      "Epoch 65: train loss=0.3298, validation loss=0.3314\n",
      "Epoch 66: train loss=0.3296, validation loss=0.3293\n",
      "Epoch 67: train loss=0.3302, validation loss=0.3328\n",
      "Epoch 68: train loss=0.3300, validation loss=0.3310\n",
      "Epoch 69: train loss=0.3295, validation loss=0.3437\n",
      "Epoch 70: train loss=0.3294, validation loss=0.3302\n",
      "Epoch 71: train loss=0.3299, validation loss=0.3299\n",
      "Epoch 72: train loss=0.3295, validation loss=0.3305\n",
      "Epoch 73: train loss=0.3292, validation loss=0.3322\n",
      "Epoch 74: train loss=0.3297, validation loss=0.3295\n",
      "Epoch 75: train loss=0.3294, validation loss=0.3290\n",
      "Epoch 76: train loss=0.3299, validation loss=0.3359\n",
      "Epoch 77: train loss=0.3287, validation loss=0.3314\n",
      "Epoch 78: train loss=0.3289, validation loss=0.3291\n",
      "Epoch 79: train loss=0.3290, validation loss=0.3294\n",
      "Epoch 80: train loss=0.3285, validation loss=0.3332\n",
      "Epoch 81: train loss=0.3285, validation loss=0.3303\n",
      "Epoch 82: train loss=0.3283, validation loss=0.3307\n",
      "Epoch 83: train loss=0.3284, validation loss=0.3288\n",
      "Epoch 84: train loss=0.3284, validation loss=0.3287\n",
      "Epoch 85: train loss=0.3279, validation loss=0.3292\n",
      "Epoch 86: train loss=0.3285, validation loss=0.3305\n",
      "Epoch 87: train loss=0.3287, validation loss=0.3291\n",
      "Epoch 88: train loss=0.3280, validation loss=0.3291\n",
      "Epoch 89: train loss=0.3280, validation loss=0.3284\n",
      "Epoch 90: train loss=0.3278, validation loss=0.3301\n",
      "Epoch 91: train loss=0.3282, validation loss=0.3308\n",
      "Epoch 92: train loss=0.3279, validation loss=0.3278\n",
      "Epoch 93: train loss=0.3277, validation loss=0.3294\n",
      "Epoch 94: train loss=0.3278, validation loss=0.3284\n",
      "Epoch 95: train loss=0.3274, validation loss=0.3323\n",
      "Epoch 96: train loss=0.3279, validation loss=0.3292\n",
      "Epoch 97: train loss=0.3279, validation loss=0.3291\n",
      "Epoch 98: train loss=0.3276, validation loss=0.3278\n",
      "Epoch 99: train loss=0.3273, validation loss=0.3315\n",
      "Epoch 100: train loss=0.3275, validation loss=0.3281\n",
      "Training complete. Total time: 1225.1s.\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc16252-f4ae-4027-88ef-23b258ee0ffd",
   "metadata": {},
   "source": [
    "### Now let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "256fe45c-70dc-46b6-a9db-1a8661a8bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data('top',input_folder,batch=128,dataset_type='test')\n",
    "predictions, labels = trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6737db7-d095-4762-a2fd-2b38aec08642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9243\n",
      "\n",
      "ACC: 0.8906\n",
      "\n",
      "Signal class 1 vs Background class 0:\n",
      "Class 1 effS at 0.30004107507831485 1.0/effB = 21.101484113712374\n",
      "Class 1 effS at 0.5000668088623194 1.0/effB = 15.395684001830105\n"
     ]
    }
   ],
   "source": [
    "utils.print_metrics(predictions,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf68ae8-ff04-46e5-abbb-5a355a81cd19",
   "metadata": {},
   "source": [
    "### Try changing the hyperparameters, activation functions, layers, learning rate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43f5199-b373-4e1b-88cb-66e823f1f076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.6.0",
   "language": "python",
   "name": "pytorch-2.6.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
